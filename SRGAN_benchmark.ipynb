{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7cHmhUmaZ_-",
        "outputId": "ef2a070c-18ab-4200-b83b-2b1e0ec6d930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# zip_path = '/content/drive/MyDrive/Dataset.zip'\n",
        "# extract_path = '/content/data/test'\n",
        "\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n"
      ],
      "metadata": {
        "id": "AYM8pkNqacvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall piq completely\n",
        "!pip uninstall -y piq\n",
        "\n",
        "# Clean up any cached versions\n",
        "!rm -rf piq\n",
        "\n",
        "# Clone the latest PIQ with niqe support\n",
        "!git clone https://github.com/photosynthesis-team/piq.git\n",
        "\n",
        "# Move into the directory\n",
        "%cd piq\n",
        "\n",
        "# Install from source\n",
        "!pip install . --quiet\n",
        "\n",
        "# Return to your working directory\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17IRtqLvJKG",
        "outputId": "61c6d8d7-f6f6-4706-ef81-7dc7a9d8d016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping piq as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCloning into 'piq'...\n",
            "remote: Enumerating objects: 2289, done.\u001b[K\n",
            "remote: Counting objects: 100% (891/891), done.\u001b[K\n",
            "remote: Compressing objects: 100% (502/502), done.\u001b[K\n",
            "remote: Total 2289 (delta 587), reused 636 (delta 380), pack-reused 1398 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2289/2289), 3.80 MiB | 26.86 MiB/s, done.\n",
            "Resolving deltas: 100% (1474/1474), done.\n",
            "/content/piq\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for piq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from piq import LPIPS\n",
        "print(\"✅ NIQE and LPIPS imported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfaKeEeqvLEp",
        "outputId": "4b226305-9f68-41d9-8a44-81b60d07e9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NIQE and LPIPS imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from math import log10\n",
        "from math import exp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as utils\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "import math"
      ],
      "metadata": {
        "id": "GXf4auTJR0we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n"
      ],
      "metadata": {
        "id": "ZlBXZVlKUVjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "\n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "metadata": {
        "id": "4MMUov0QTciD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "AzIQzgpMSD4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(TestDatasetFromFolder, self).__init__()\n",
        "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
        "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.filenames = sorted([\n",
        "            f for f in os.listdir(self.lr_path)\n",
        "            if is_image_file(f) and os.path.exists(os.path.join(self.hr_path, f))\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        lr_image = Image.open(os.path.join(self.lr_path, filename)).convert('RGB')\n",
        "        w, h = lr_image.size\n",
        "        hr_image = Image.open(os.path.join(self.hr_path, filename)).convert('RGB')\n",
        "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return filename, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)"
      ],
      "metadata": {
        "id": "GILvJuFnSTnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPn3hw8rRrsF",
        "outputId": "2eb517bd-6f2c-4d97-e9f8-e78ba5feaf6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/photosynthesis-team/photosynthesis.metrics/releases/download/v0.4.0/lpips_weights.pt\" to /root/.cache/torch/hub/checkpoints/lpips_weights.pt\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "[testing benchmark datasets]:   0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-10-25a3fede7dd0>:27: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  lr_image = Variable(lr_image, volatile=True)\n",
            "<ipython-input-10-25a3fede7dd0>:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  hr_image = Variable(hr_image, volatile=True)\n",
            "[testing benchmark datasets]: 100%|██████████| 19/19 [00:09<00:00,  1.94it/s]\n"
          ]
        }
      ],
      "source": [
        "UPSCALE_FACTOR = 4\n",
        "MODEL_NAME = \"netG_epoch_4_157.pth\"\n",
        "\n",
        "results = {'Set5': {'psnr': [], 'ssim': [],'lpips' : []}, 'Set14': {'psnr': [], 'ssim': [],'lpips' : []}, 'BSD100': {'psnr': [], 'ssim': [],'lpips' : []},\n",
        "           'Urban100': {'psnr': [], 'ssim': [],'lpips' : []}, 'SunHays80': {'psnr': [], 'ssim': [],'lpips' : []}}\n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "model.load_state_dict(torch.load('/content/epochs/' + MODEL_NAME))\n",
        "\n",
        "lpips_model = LPIPS(reduction='mean')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    lpips_model = lpips_model.cuda()\n",
        "\n",
        "test_set = TestDatasetFromFolder('/content/data/test/Dataset', upscale_factor=UPSCALE_FACTOR)\n",
        "test_loader = DataLoader(dataset=test_set, num_workers=2, batch_size=1, shuffle=False)\n",
        "test_bar = tqdm(test_loader, desc='[testing benchmark datasets]')\n",
        "\n",
        "out_path = 'benchmark_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "\n",
        "for image_name, lr_image, hr_restore_img, hr_image in test_bar:\n",
        "    image_name = image_name[0]\n",
        "    lr_image = Variable(lr_image, volatile=True)\n",
        "    hr_image = Variable(hr_image, volatile=True)\n",
        "    if torch.cuda.is_available():\n",
        "        lr_image = lr_image.cuda()\n",
        "        hr_image = hr_image.cuda()\n",
        "\n",
        "    sr_image = model(lr_image)\n",
        "    mse = ((hr_image - sr_image) ** 2).data.mean()\n",
        "    psnr = 10 * log10(1 / mse)\n",
        "    lpips_score = lpips_model(sr_image, hr_image)\n",
        "    calculated_ssim  = ssim(sr_image, hr_image).item()\n",
        "\n",
        "    test_images = torch.stack(\n",
        "        [display_transform()(hr_restore_img.squeeze(0)), display_transform()(hr_image.data.cpu().squeeze(0)),\n",
        "         display_transform()(sr_image.data.cpu().squeeze(0))])\n",
        "    image = utils.make_grid(test_images, nrow=3, padding=5)\n",
        "    utils.save_image(image, out_path + image_name.split('.')[0] + '_psnr_%.4f_ssim_%.4f.' % (psnr, calculated_ssim) +\n",
        "                     image_name.split('.')[-1], padding=5)\n",
        "\n",
        "    results[image_name.split('_')[0]]['psnr'].append(psnr)\n",
        "    results[image_name.split('_')[0]]['ssim'].append(calculated_ssim)\n",
        "    results[image_name.split('_')[0]]['lpips'].append(lpips_score)\n",
        "\n",
        "out_path = 'statistics/'\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)\n",
        "saved_results = {'psnr': [], 'ssim': [],'lpips' : []}\n",
        "for item in results.values():\n",
        "    psnr = np.array(item['psnr'])\n",
        "    calculated_ssim = np.array(item['ssim'])\n",
        "    if len(item['lpips']) > 0:\n",
        "        lpips_score = np.array([score.detach().cpu().numpy() for score in item['lpips']])\n",
        "    else:\n",
        "        lpips_score = np.array([])\n",
        "    if (len(psnr) == 0) or (len(calculated_ssim) == 0) or (len(lpips_score) == 0):\n",
        "        psnr = 'No data'\n",
        "        calculated_ssim = 'No data'\n",
        "        lpips_score = 'No data'\n",
        "    else:\n",
        "        psnr = psnr.mean()\n",
        "        calculated_ssim = calculated_ssim.mean()\n",
        "        lpips_score = lpips_score.mean()\n",
        "    saved_results['psnr'].append(psnr)\n",
        "    saved_results['ssim'].append(calculated_ssim)\n",
        "    saved_results['lpips'].append(lpips_score)\n",
        "\n",
        "data_frame = pd.DataFrame(saved_results, results.keys())\n",
        "data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_test_results.csv', index_label='DataSet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# shutil.make_archive('/content/statistics', 'zip', '/content/statistics')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YeDpMfnQzi2B",
        "outputId": "0ace5815-9844-47da-a648-2a31bb2ad914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/statistics.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}